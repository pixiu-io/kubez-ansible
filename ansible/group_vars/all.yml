---
########################
# Kubez-ansible Options
########################
network_interface: "eth0"
api_interface: "{{ network_interface }}"
api_interface_address: "{{ hostvars[inventory_hostname]['ansible_' + api_interface]['ipv4']['address'] }}"

aliyun_repo: "registry.cn-hangzhou.aliyuncs.com/google_containers"
image_repository: "{{ aliyun_repo }}"

enable_registry: "no"
registry_server: 127.0.0.1:4000
registry_namespace: "kubernetes"
registry_repo: "{{ registry_server }}/{{ registry_namespace }}"

#####################
# keepalived options
#####################
# Arbitrary unique number from 0..255
keepalived_virtual_router_id: "68"

#####################
# Kubernetes Options
#####################
kube_application_dir: "/tmp/kubezspace"
kubez_namespace: kubez-sysns

# This should be a VIP, an unused IP on your network that will float between
# the hosts running keepalived for high-availability.
kube_vip_address: 172.16.50.250
dashboard_vip_address: ""

kube_vip_port: 8443
dashboard_node_port: 30001
ingress_node_port: 30006
ingress_tls_node_port: 30008

cluster_cidr: "172.30.0.0/16"
service_cidr: "10.254.0.0/16"

# Kubernetes network cni options
enable_flannel: "{{ not enable_calico | bool }}"
enable_calico: "no"

enable_kubernetes: "yes"
enable_kubernetes_ha: "no"
enable_haproxy: "{{ enable_kubernetes_ha }}"
enable_metrics_server: "yes"
enable_nfs_provisioner: "{{ enable_nfs }}"
enable_rbd_provisioner: "no"
enable_dashboard: "no"
enable_ingress_nginx: "yes"
enable_helm: "yes"

kube_release: 1.18.6
kube_release_ubuntu: 1.18.6-00
kubernetes_version: "v{{ kube_release }}"

# runtime docker version
docker_release: 18.06.2
docker_release_ubuntu: 18.06.2~ce~3-0~ubuntu

# runtime containerd version
containerd_release: 1.4.3
containerd_release_ubuntu: 1.4.3-1

helm_release: v3.0.3

node_config_directory: "/etc/kubez/"

kube_repo: "{{ registry_repo if enable_registry | bool else image_repository }}"

kube_applications:
  # kubez-sysns should exists before the other applications created
  - name: kubez-sysns
    enabled: "yes"
  - name: kube-flannel
    enabled: "{{ enable_flannel | bool }}"
  - name: kube-calico
    enabled: "{{ enable_calico | bool }}"
  - name: dashboard
    enabled: "{{ enable_dashboard | bool }}"
  - name: metrics-server
    enabled: "{{ enable_metrics_server | bool }}"
  - name: nfs-provisioner
    enabled: "{{ enable_nfs_provisioner | bool }}"
  - name: rbd-provisioner
    enabled: "{{ enable_rbd_provisioner | bool }}"
  - name: ingress-nginx
    enabled: "{{ enable_ingress_nginx | bool }}"
  - name: jenkins
    enabled: "{{ enable_jenkins | bool }}"

#####################
# Application Images
#####################
metrics_server_images:
  - "{{ image_repository }}/metrics-server-amd64:v0.3.6"
  - "{{ image_repository }}/addon-resizer:1.8.6"

flannel_url: "{{ registry_server if enable_registry | bool else 'quay.io' }}"
flannel_amd64_image: "{{ flannel_url }}/coreos/flannel:v0.11.0-amd64"
flannel_arm64_image: "{{ flannel_url }}/coreos/flannel:v0.11.0-arm64"
flannel_arm_image: "{{ flannel_url }}/coreos/flannel:v0.11.0-arm"
flannel_ppc64le_image: "{{ flannel_url }}/coreos/flannel:v0.11.0-ppc64le"
flannel_s390x_image: "{{ flannel_url }}/coreos/flannel:v0.11.0-s390x"

calico_url: "{{ registry_server + '/' if enable_registry | bool else '' }}"
calico_tag: v3.12.0
calico_node_image: "{{ calico_url }}calico/node:{{ calico_tag }}"
calico_cni_image: "{{ calico_url }}calico/cni:{{ calico_tag }}"
calico_pod2daemon_flexvol_image: "{{ calico_url }}calico/pod2daemon-flexvol:{{ calico_tag }}"
calico_kube_controllers_image: "{{ calico_url }}calico/kube-controllers:{{ calico_tag }}"

dashboard_url: "{{ registry_server + '/kubernetes' if enable_registry | bool else image_repository }}"
dashboard_image: "{{ dashboard_url }}/kubernetes-dashboard-amd64:v1.10.1"

nfs_provisioner_url: "{{ registry_server if enable_registry | bool else 'quay.io' }}"
nfs_provisioner_image: "{{ nfs_provisioner_url }}/external_storage/nfs-client-provisioner:latest"

rbd_provisioner_url: "{{ registry_server if enable_registry | bool else 'quay.io' }}"
rbd_provisioner_image: "{{ rbd_provisioner_url }}/external_storage/rbd-provisioner"

fluentd_url: "{{ registry_server if enable_registry | bool else 'quay.io' }}"
fluentd_image: "{{ fluentd_url }}/fluentd_elasticsearch/fluentd:v2.7.0"

kibana_url: "{{ registry_server if enable_registry | bool else 'docker.elastic.co' }}"
kibana_image: "{{ kibana_url }}/kibana/kibana-oss:7.2.0"

elasticsearch_url: "{{ registry_server if enable_registry | bool else 'quay.io' }}"
elasticsearch_image: "{{ elasticsearch_url }}/fluentd_elasticsearch/elasticsearch:v7.2.0"

alpine_url: "{{ registry_server + '/fluentd_elasticsearch/' if enable_registry | bool else '' }}"
alpine_image: "{{ alpine_url }}alpine:3.6"

nginx_ingress_url: "{{ registry_server + '/ingress' if enable_registry | bool else 'jacky06' }}"
nginx_ingress_image: "{{ nginx_ingress_url }}/nginx-ingress-controller:0.30.0"

helm_url: "{{ registry_server + '/' if enable_registry | bool else '' }}"
helm_image: "{{ helm_url }}jacky06/helm-toolbox:{{ helm_release }}"

#######################
# StorageClass Options
#######################
enable_nfs: "yes"

nfs_volume: /data/share
nfs_cidr: "*"

pool_name: kube
user_id: "{{ pool_name }}"

# Ceph monitors, comma delimited. This parameter is required.
monitors: 172.16.60.102:6789

# ceph auth get-key client.admin | base64
admin_key: QVFDTWhUcGVVUWZrRXhBQUwyVTNMdTdQSk5WRkxUMTczb3ovcFE9PQ==

# ceph osd pool create pool_name 8 8
# ceph auth add client.pool_name mon 'allow r' osd 'allow rwx pool=pool_name'
# ceph auth get-key client.pool_name | base64
ceph_key: QVFCdzN6NWVGMjJCTFJBQVcvMkU2a051UW1JSHU1VTRXZ2ZEd3c9PQ==

##########################
# Kube-prometheus Options
##########################
# https://github.com/prometheus-operator/kube-prometheus
# version is v0.6.0
# grafana will also be deploy when prometheus is enable.
enable_prometheus: "no"

################################
# Fluentd-elasticsearch Options
################################
# https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/fluentd-elasticsearch/README.md
# The Fluentd, elasticsearch, and kibana will be installed when enabled.
enable_fluentd_elasticsearch: "no"

#################
# Gerrit Options
#################
enable_gerrit: "no"
gerrit_name: gerrit
gerrit_namespace: "{{ kubez_namespace }}"
gerrit_service_type: NodePort

##################
# Jenkins Options
##################
enable_jenkins: "no"
jenkins_namespace: "{{ kubez_namespace }}"
jenkins_node_port: 30010

#################
# Harbor Options
#################
enable_harbor: "no"
harbor_name: kubez
harbor_namespace: "{{ kubez_namespace }}"
expose_nodeport: 30011

# Valid options are [ ingress, nodePort ]
expose_type: nodePort
expose_core_domain: core.harbor.kubez.com
expose_notary_domain: notary.harbor.kubez.com
harbor_storage_class: managed-nfs-storage

##################
# Mariadb Options
##################
enable_mariadb: "no"
mariadb_name: mariadb
mariadb_namespace: "{{ kubez_namespace }}"
mariadb_storage_class: managed-nfs-storage

###############
# Kong Options
###############
enable_kong: "no"
kong_name: kong
kong_namespace: "{{ kubez_namespace }}"
kong_storage_class: managed-nfs-storage

#################
# Redis Options
#################
enable_redis: "no"
redis_name: redis
redis_namespace: "{{ kubez_namespace }}"
redis_storage_class: managed-nfs-storage

##########################
# Helm Chart Applications
##########################
chart_applications:
  # gerrit
  - name: "{{ gerrit_name }}"
    namespace: "{{ gerrit_namespace }}"
    chart: gerrit
    release_enabled: "{{ enable_gerrit }}"
    chart_extra_vars:
      gerrit.service.type: "{{ gerrit_service_type }}"
  # harbor
  - name: "{{ harbor_name }}"
    namespace: "{{ harbor_namespace }}"
    chart: harbor
    release_enabled: "{{ enable_harbor }}"
    chart_extra_vars:
      expose.type: "{{ expose_type }}"
      expose.tls.enabled: 'false'
      expose.nodePort.ports.http.nodePort: "{{ '' if expose_type == 'ingress' else expose_nodeport }}"
      expose.ingress.hosts.core: "{{ expose_core_domain if expose_type == 'ingress' else '' }}"
      expose.ingress.hosts.notary: "{{ expose_notary_domain if expose_type == 'ingress' else '' }}"
      persistence.persistentVolumeClaim.registry.storageClass: "{{ harbor_storage_class }}"
      persistence.persistentVolumeClaim.chartmuseum.storageClass: "{{ harbor_storage_class }}"
      persistence.persistentVolumeClaim.jobservice.storageClass: "{{ harbor_storage_class }}"
      persistence.persistentVolumeClaim.database.storageClass: "{{ harbor_storage_class }}"
      persistence.persistentVolumeClaim.redis.storageClass: "{{ harbor_storage_class }}"
      persistence.persistentVolumeClaim.trivy.storageClass: "{{ harbor_storage_class }}"
      externalURL: "{{ 'https://' if expose_type == 'ingress' else 'http://' }}{{ expose_core_domain if expose_type == 'ingress' else hostvars[groups['kube-master'][0]]['ansible_' + network_interface]['ipv4']['address'] }}{{ '' if expose_type == 'ingress' else ':' }}{{ '' if expose_type == 'ingress' else expose_nodeport }}"
  # mariadb
  - name: "{{ mariadb_name }}"
    namespace: "{{ mariadb_namespace }}"
    chart: mariadb
    release_enabled: "{{ enable_mariadb }}"
    chart_extra_vars:
      global.storageClass: "{{ mariadb_storage_class }}"
      primary.persistence.storageClass: "{{ mariadb_storage_class }}"
      secondary.persistence.storageClass: "{{ mariadb_storage_class }}"
  # kong
  - name: "{{ kong_name }}"
    namespace: "{{ kong_namespace }}"
    chart: kong
    release_enabled: "{{ enable_kong }}"
    chart_extra_vars: {}
  # redis
  - name: "{{ redis_name }}"
    namespace: "{{ redis_namespace }}"
    chart: redis
    release_enabled: "{{ enable_redis }}"
    chart_extra_vars:
      global.storageClass: "{{ redis_storage_class }}"
      master.persistence.storageClass: "{{ redis_storage_class }}"
      slave.persistence.storageClass: "{{ redis_storage_class }}"
